{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0479144c",
   "metadata": {},
   "source": [
    "# üìò Feature Engineering & Encoding Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1c2e2",
   "metadata": {},
   "source": [
    "### **üéØ Objective**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904f6d3",
   "metadata": {},
   "source": [
    "Convert the cleaned dataset into a model-ready feature matrix by encoding categorical variables and assembling numeric features without re-cleaning, scaling, or leakage. This notebook produces a stable features artifact for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778bc9c",
   "metadata": {},
   "source": [
    "### Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54904c1",
   "metadata": {},
   "source": [
    "###  Notebook\n",
    "\n",
    "**File:** `notebooks/03_feature_engineering.ipynb`\n",
    "\n",
    "**Stage:** Feature Engineering & Encoding\n",
    "\n",
    "**Input Contract:** `data/processed/nwmp_cleaned_v1.csv`\n",
    "\n",
    "**Output Contract:** `data/processed/nwmp_features_v1.(csv | parquet)`\n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "\n",
    "Transform the **cleaned and validated dataset** into a **model-ready feature matrix** by:\n",
    "\n",
    "* encoding categorical variables,\n",
    "* assembling numeric and engineered features,\n",
    "* enforcing strict schema invariants,\n",
    "\n",
    "**without performing cleaning, imputation, scaling, or modeling decisions.**\n",
    "\n",
    "This notebook establishes a **stable, reusable feature representation** for all downstream models.\n",
    "\n",
    "---\n",
    "\n",
    "### Input Assumptions (Contract Enforcement)\n",
    "\n",
    "The input dataset satisfies the following invariants:\n",
    "\n",
    "* ‚úÖ No missing values (NaNs)\n",
    "* ‚úÖ Leakage-prone, metadata, and sparse columns already removed\n",
    "* ‚úÖ Numeric features properly typed\n",
    "* ‚úÖ BDL (Below Detection Limit) information preserved as binary flags\n",
    "* ‚úÖ One row = one observation\n",
    "* ‚úÖ Target variable (`use_based_class`) present and clean\n",
    "\n",
    "If any of these conditions fail, the pipeline must return to **data cleaning**.\n",
    "\n",
    "---\n",
    "\n",
    "### Feature Engineering Scope\n",
    "\n",
    "#### Included Operations\n",
    "\n",
    "* Target separation (`X`, `y`)\n",
    "* Identification of categorical features\n",
    "* One-hot encoding of low-cardinality categorical columns\n",
    "* Assembly of numeric + encoded categorical features\n",
    "* Schema validation (row alignment, NaN checks)\n",
    "* Export of model-ready feature matrix\n",
    "\n",
    "#### Explicitly Excluded Operations\n",
    "\n",
    "* ‚ùå Data cleaning or imputation\n",
    "* ‚ùå Column dropping or leakage decisions\n",
    "* ‚ùå Feature scaling or normalization\n",
    "* ‚ùå Outlier handling\n",
    "* ‚ùå Feature selection\n",
    "* ‚ùå Model training\n",
    "\n",
    "---\n",
    "\n",
    "### Feature Composition\n",
    "\n",
    "#### Numeric Features\n",
    "\n",
    "* Physicochemical parameters (pH, DO, conductivity, TDS, turbidity, etc.)\n",
    "* Chemical contaminants (nutrients, ions, hardness, alkalinity)\n",
    "* Biological indicators (fecal coliform, total coliform, streptococci)\n",
    "* Engineered **BDL indicator flags** (`*_is_bdl`)\n",
    "\n",
    "All numeric features are passed through **unchanged**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Categorical Features\n",
    "\n",
    "* Domain-relevant, low-cardinality features only\n",
    "* Encoded using **one-hot encoding**\n",
    "* No identifiers, metadata, or leakage-prone columns included\n",
    "\n",
    "High-cardinality or free-text columns are intentionally excluded upstream.\n",
    "\n",
    "---\n",
    "\n",
    "### Validation & Safety Checks\n",
    "\n",
    "Before export, the following conditions are enforced:\n",
    "\n",
    "* Feature matrix contains **no missing values**\n",
    "* Feature rows align exactly with target labels\n",
    "* No duplicate rows introduced during encoding\n",
    "\n",
    "These checks ensure downstream models receive a **stable and deterministic input**.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Artifact\n",
    "\n",
    "The notebook exports a single, versioned feature dataset:\n",
    "\n",
    "* **CSV (mandatory):** transparent, debuggable\n",
    "* **Parquet (optional):** optimized for performance and scale\n",
    "\n",
    "This artifact represents the **final feature contract** for all modeling notebooks.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Design Principles\n",
    "\n",
    "* **Separation of concerns:**\n",
    "  Cleaning ‚Üí Feature Engineering ‚Üí Modeling are strictly isolated.\n",
    "\n",
    "* **Reproducibility:**\n",
    "  Feature generation is deterministic and independent of model choice.\n",
    "\n",
    "* **Leakage safety:**\n",
    "  Only features that exist prior to labeling are included.\n",
    "\n",
    "* **Scalability:**\n",
    "  Same features can be reused across multiple models and experiments.\n",
    "\n",
    "---\n",
    "\n",
    "### Status\n",
    "\n",
    "‚úÖ Feature engineering complete\n",
    "‚úÖ Schema validated\n",
    "‚úÖ Model-ready dataset exported\n",
    "üü¢ **Ready for model training**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a5dae5",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dae5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c999ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import DATA_DIR # Path to raw data source\n",
    "from src.data_preprocessing.create_dataframe import create_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae9265",
   "metadata": {},
   "source": [
    "### **üíø Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c574fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded cleaned dataset\n",
      "(171, 56)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING ‚Äî CLEANED CONTRACT INPUT\n",
    "# ============================================================================\n",
    "\n",
    "INPUT_CSV = os.path.join(DATA_DIR, \"processed\", \"csv\", \"cleaned_water_quality_data.csv\")\n",
    "# Optional parquet if available:\n",
    "# INPUT_PARQUET = os.path.join(DATA_DIR, \"processed\", \"parquet\", \"cleaned_water_quality_data.parquet\")\n",
    "\n",
    "df = create_dataframe(INPUT_CSV)\n",
    "\n",
    "print(\"‚úì Loaded cleaned dataset\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a38937e",
   "metadata": {},
   "source": [
    "### **Define Target & Separate Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb89e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Features / target separated\n",
      "X shape: (171, 55) | y shape: (171,)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TARGET SEPARATION\n",
    "# ============================================================================\n",
    "\n",
    "TARGET_COL = \"use_based_class\"\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL].copy()\n",
    "\n",
    "print(\"‚úì Features / target separated\")\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b2675",
   "metadata": {},
   "source": [
    "### Feature Engineering (Encoding Scope Only)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c590044",
   "metadata": {},
   "source": [
    "**3.1 Identify categorical columns to encode**\n",
    "\n",
    "(Low-cardinality only; no identifiers, no leakage, no free-text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b690f5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns to encode: ['type_water_body', 'river_basin', 'district', 'weather', 'approx_depth', 'human_activities', 'floating_matter', 'color', 'odor']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CATEGORICAL FEATURE SELECTION (ENCODING SCOPE)\n",
    "# ============================================================================\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "# Explicit exclusions (already decided in EDA / cleaning)\n",
    "EXCLUDE_CATS = [\n",
    "    # identifiers / metadata / free-text already removed upstream\n",
    "]\n",
    "\n",
    "# Keep only safe, low-cardinality categories\n",
    "encode_cats = [c for c in categorical_cols if c not in EXCLUDE_CATS]\n",
    "\n",
    "print(\"Categorical columns to encode:\", encode_cats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca05483",
   "metadata": {},
   "source": [
    "### One-hot encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "389e6ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Encoding complete\n",
      "Encoded shape: (171, 179)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ONE-HOT ENCODING (NO SCALING, NO LEAKAGE)\n",
    "# ============================================================================\n",
    "\n",
    "X_encoded = pd.get_dummies(\n",
    "    X,\n",
    "    columns=encode_cats,\n",
    "    drop_first=False\n",
    ")\n",
    "\n",
    "print(\"‚úì Encoding complete\")\n",
    "print(\"Encoded shape:\", X_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ac5ed",
   "metadata": {},
   "source": [
    "### Assemble Feature Matrix (No Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc1680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Feature matrix assembled and validated\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FINAL FEATURE MATRIX\n",
    "# ============================================================================\n",
    "\n",
    "X_features = X_encoded.copy()\n",
    "\n",
    "# Invariants\n",
    "assert X_features.isna().sum().sum() == 0, \"NaNs present after encoding\"\n",
    "assert X_features.shape[0] == y.shape[0], \"Row mismatch between X and y\"\n",
    "\n",
    "print(\"‚úì Feature matrix assembled and validated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2aec1",
   "metadata": {},
   "source": [
    "### Export Model-Ready Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac18033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Features exported to /Users/rex/Documents/personal/AquaSafe/data/processed/csv/nwmp_features_v1.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXPORT FEATURES (MODEL-READY, UN-SCALED)\n",
    "# ============================================================================\n",
    "\n",
    "OUT_CSV = os.path.join(DATA_DIR, \"processed\", \"csv\", \"nwmp_features_v1.csv\")\n",
    "OUT_PARQUET = os.path.join(DATA_DIR, \"processed\", \"parquet\", \"nwmp_features_v1.parquet\")\n",
    "\n",
    "X_features.assign(**{TARGET_COL: y}).to_csv(OUT_CSV, index=False)\n",
    "\n",
    "try:\n",
    "    X_features.assign(**{TARGET_COL: y}).to_parquet(OUT_PARQUET, index=False)\n",
    "except Exception as e:\n",
    "    print(\"Parquet export skipped:\", e)\n",
    "\n",
    "print(f\"‚úì Features exported to {OUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
